#include "playlib.h"#include "stdlib.h"#include "stdio.h"#include "include/libavutil/pixfmt.h"#include "include/libswscale/swscale.h"#include "include/libavformat/avformat.h"#include "include/libavcodec/avcodec.h"#include "include/libavdevice/avdevice.h"#define TAG "57"#include <android/log.h>#define LOGD(...) __android_log_print(ANDROID_LOG_DEBUG,TAG ,__VA_ARGS__) // 定义LOGD类型#define LOGI(...) __android_log_print(ANDROID_LOG_INFO,TAG ,__VA_ARGS__) // 定义LOGI类型#define LOGW(...) __android_log_print(ANDROID_LOG_WARN,TAG ,__VA_ARGS__) // 定义LOGW类型#define LOGE(...) __android_log_print(ANDROID_LOG_ERROR,TAG ,__VA_ARGS__) // 定义LOGE类型#define LOGF(...) __android_log_print(ANDROID_LOG_FATAL,TAG ,__VA_ARGS__) // 定义LOGF类型void ffmpeg_init(){  //av_register_all();  avcodec_register_all();}void ffmpeg_done(){  //avcodec_register_all();  }int video_began(int video_format, int image_width, int image_height, long* vd_handle){    videodecode_t* vd = (videodecode_t*)malloc(sizeof(videodecode_t));    if(vd == 0)      return -1;    memset(vd,0,sizeof(sizeof(videodecode_t)));    *vd_handle = (long)vd;    enum AVCodecID codeId = AV_CODEC_ID_NONE;    switch(video_format)    {    case VIDEO_FORMAT_H264:      codeId = AV_CODEC_ID_H264;      break;    case VIDEO_FORMAT_MJPEG:      codeId = AV_CODEC_ID_MJPEG;      break;    default:      return -2;    }    vd->mAVCodec = avcodec_find_decoder(codeId);    if(!vd->mAVCodec)    {        return -3;    }    vd->mAVCodecContext = avcodec_alloc_context3(vd->mAVCodec);    if(!vd->mAVCodecContext)    {        return -4;    }    vd->mAVCodecContext->width = image_width;    vd->mAVCodecContext->height = image_height;    vd->mAVCodecContext->pix_fmt = AV_PIX_FMT_YUV420P;    if (avcodec_open2(vd->mAVCodecContext, vd->mAVCodec, 0) < 0) // ��Ҫ����    {        return -5;    }    vd->mAVFrame = av_frame_alloc();    if (!vd->mAVFrame)    {        return -6;    }    if(avpicture_alloc(&vd->mAVPicture, AV_PIX_FMT_RGB565LE, vd->mAVCodecContext->width, vd->mAVCodecContext->height)<0)    {        return -7;    }        vd->mSwsContext = sws_getCachedContext(0,                                               vd->mAVCodecContext->width,                                               vd->mAVCodecContext->height,                                               vd->mAVCodecContext->pix_fmt,                                               vd->mAVCodecContext->width,          // ����ͼ��Ŀ��                                               vd->mAVCodecContext->height,         // ����ͼ��ĸ߶�                                               AV_PIX_FMT_RGB565LE,                                               SWS_FAST_BILINEAR, NULL, NULL, NULL);//SWS_POINT?  return 0;}void video_ended(long* vd_handle){    if (*vd_handle == 0)        return ;    videodecode_t* vd = (videodecode_t*)*vd_handle;    if(vd->mAVCodecContext)    {        avcodec_close(vd->mAVCodecContext); // ��Ҫ����        av_free(vd->mAVCodecContext);        vd->mAVCodecContext = 0;    }    if(vd->mAVFrame)    {        av_free(vd->mAVFrame);        vd->mAVFrame = 0;    }    avpicture_free(&vd->mAVPicture);    if (vd->mSwsContext)    {        sws_freeContext(vd->mSwsContext);    }    free(vd);    vd = 0;    *vd_handle = 0;}//#include "alog.h"//#include <sys/time.h>int video_decode(long vd_handle, uint8_t* in_264Buffer, int in_264BufferSize, uint8_t* out_RGB24Buffer, int* out_image_width, int* out_image_height,int* outsize){    if (vd_handle == 0 || in_264Buffer == 0 || in_264BufferSize == 0)      return -1;     // LOGE("video_decode vd_handle = %ld",vd_handle);    videodecode_t* vd = (videodecode_t*)vd_handle;    AVPacket avpkt;    av_init_packet(&avpkt);    avpkt.data = in_264Buffer;    // packet data will be allocated by the encoder    avpkt.size = in_264BufferSize;    //struct timeval startTime;    //struct timeval endTime;    //struct timeval centerTime;    //memset(&startTime,0,sizeof(struct timeval));    //memset(&endTime,0,sizeof(struct timeval));    //memset(&centerTime,0,sizeof(struct timeval));    //gettimeofday(&startTime,NULL);    int got_picture = 0;    int consumed_bytes = avcodec_decode_video2(vd->mAVCodecContext, vd->mAVFrame, &got_picture, &avpkt);    //LOGE("consumed_bytes = %d",consumed_bytes);    av_free_packet(&avpkt);    if (consumed_bytes <= 0 || vd->mAVFrame->data[0] == 0)    {        return -2;    }    //gettimeofday(&centerTime,NULL);    // �����ݴ�pFrameд��picture֮��    sws_scale(vd->mSwsContext,              (const uint8_t *const *)vd->mAVFrame->data,              vd->mAVFrame->linesize,              0,              vd->mAVCodecContext->height,              vd->mAVPicture.data,              vd->mAVPicture.linesize);   // gettimeofday(&endTime,NULL);       //LOGE("video_decode 5");    int size = vd->mAVPicture.linesize[0] * vd->mAVCodecContext->height;    //LOGE("video_decode 5,size =%d,vd->mAVPicture.data[0]=%d,vd->mAVPicture.linesize[0]=%d",size,vd->mAVPicture.data[0],vd->mAVPicture.linesize[0]);    memcpy(out_RGB24Buffer, vd->mAVPicture.data[0], size);    //LOGE("video_decode 6 size = %d,vd->mAVPicture.data[0]=%d,out_RGB24Buffer len =%d",size,vd->mAVPicture.data[0],sizeof(out_RGB24Buffer));    *out_image_width = vd->mAVCodecContext->width;    *out_image_height = vd->mAVCodecContext->height;    *outsize = size;    //LOGE("video_decode 6 vd->mAVCodecContext->width = %d,vd->mAVCodecContext->height = %d",vd->mAVCodecContext->width,vd->mAVCodecContext->height);  return size;}